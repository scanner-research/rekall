{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Rekall Tutorial: Data Loading and Visualization\n",
    "\n",
    "In this tutorial, you'll take a deep dive into loading data into Rekall and visualizing annotations with Vgrid. We'll dive into the \"helper code\" used in the Cyclist Detection tutorial.\n",
    "\n",
    "You should complete this tutorial after the Cyclist Detection tutorial."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports\n",
    "\n",
    "So far, we've just been importing Rekall libraries in our notebooks. Now we'll also import vgrid and vgrid_jupyter (Vgrid plugin for Jupyter notebooks) into our environment. We'll also import some standard Python libraries to read data from our servers. Previously the helper code was doing this for us."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "# Rekall imports\n",
    "from rekall import Interval, IntervalSet, IntervalSetMapping, Bounds3D\n",
    "from rekall.predicates import *\n",
    "\n",
    "# Vgrid imports\n",
    "from vgrid import VGridSpec, VideoMetadata, VideoBlockFormat, FlatFormat, SpatialType_Bbox\n",
    "from vgrid_jupyter import VGridWidget\n",
    "\n",
    "# Imports to read data from external servers.\n",
    "import urllib3, requests, os, pickle, posixpath"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preview\n",
    "\n",
    "Let's first take a look at what the end product will look like. This code will load data the cyclist detection dataset and Mask R-CNN detections from GCP and visualize it. This is Intel's CyDet dataset (hence variable names and URLs).\n",
    "\n",
    "### Once the visualization is up, click it to expand it. Hover over the expanded video and use `;` to play/pause the video."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "948451b1174041ab9e772523919a5881",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VGridWidget(vgrid_spec={'compressed': True, 'data': b'x\\x9c\\xcc\\xbd\\xdb\\xae&K\\x92\\x9c\\xf7*D_\\x0bB\\x9c\\x0f\\xba\\…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "urllib3.disable_warnings()\n",
    "VIDEO_COLLECTION_BASEURL = \"https://storage.googleapis.com/esper/dan_olimar/rekall_tutorials/cydet\" \n",
    "VIDEO_METADATA_FILENAME = \"metadata.json\"\n",
    "req = requests.get(posixpath.join(VIDEO_COLLECTION_BASEURL, VIDEO_METADATA_FILENAME), verify=False)\n",
    "video_collection = sorted(req.json(), key=lambda vm: vm['filename'])\n",
    "\n",
    "video_metadata = [\n",
    "    VideoMetadata(v[\"filename\"], v[\"id\"], v[\"fps\"], int(v[\"num_frames\"]), v[\"width\"], v[\"height\"])\n",
    "    for v in video_collection\n",
    "]\n",
    "\n",
    "maskrcnn_bbox_files = [ 'maskrcnn_bboxes_0001.pkl', 'maskrcnn_bboxes_0004.pkl' ]\n",
    "\n",
    "maskrcnn_bboxes = []\n",
    "for bbox_file in maskrcnn_bbox_files:\n",
    "    req = requests.get(posixpath.join(VIDEO_COLLECTION_BASEURL, bbox_file), verify=False)\n",
    "    maskrcnn_bboxes.append(pickle.loads(req.content))\n",
    "\n",
    "# Load Mask R-CNN data into Rekall\n",
    "maskrcnn_bboxes_ism = IntervalSetMapping({\n",
    "    vm.id: IntervalSet([\n",
    "        Interval(\n",
    "            Bounds3D(\n",
    "                t1 = frame_num / vm.fps,\n",
    "                t2 = (frame_num + 1) / vm.fps,\n",
    "                x1 = bbox[0] / vm.width,\n",
    "                x2 = bbox[2] / vm.width,\n",
    "                y1 = bbox[1] / vm.height,\n",
    "                y2 = bbox[3] / vm.height\n",
    "            ),\n",
    "            payload = {\n",
    "                'class': bbox[4],\n",
    "                'score': bbox[5],\n",
    "                'spatial_type': SpatialType_Bbox(text=bbox[4])\n",
    "            }\n",
    "        )\n",
    "        for frame_num, bboxes_in_frame in enumerate(maskrcnn_frame_list)\n",
    "        for bbox in bboxes_in_frame\n",
    "    ])\n",
    "    for vm, maskrcnn_frame_list in zip(video_metadata, maskrcnn_bboxes)\n",
    "})\n",
    "\n",
    "# Visualize the data\n",
    "vgrid_spec = VGridSpec(\n",
    "    video_meta = video_metadata,\n",
    "    vis_format = VideoBlockFormat(imaps = [\n",
    "        ('bboxes', maskrcnn_bboxes_ism)\n",
    "    ]),\n",
    "    video_endpoint = VIDEO_COLLECTION_BASEURL\n",
    ")\n",
    "VGridWidget(vgrid_spec = vgrid_spec.to_json_compressed())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Code Walkthrough\n",
    "Now let's walk through the above code bit by bit to get an idea of what's going on."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Video metadata\n",
    "\n",
    "First we need to get some metadata about the individual videos that we're visualizing. In particular, we need to know the **FPS, duration, width, and height** of each video in order to display them using Vgrid. In our case, we've already computed these things for our driving videos, but you can also use [this script](https://github.com/scanner-research/esperlight/blob/master/create_video_metadata.py) to compute them for you (`fmpeg/ffprobe` are dependencies).\n",
    "\n",
    "### This code loads pre-computed FPS, duration, width, and height of each video and puts them into `VideoMetadata` objects:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "urllib3.disable_warnings()\n",
    "VIDEO_COLLECTION_BASEURL = \"https://storage.googleapis.com/esper/dan_olimar/rekall_tutorials/cydet\" \n",
    "VIDEO_METADATA_FILENAME = \"metadata.json\"\n",
    "\n",
    "req = requests.get(posixpath.join(VIDEO_COLLECTION_BASEURL, VIDEO_METADATA_FILENAME), verify=False)\n",
    "video_collection = sorted(req.json(), key=lambda vm: vm['filename'])\n",
    "\n",
    "video_metadata = [\n",
    "    VideoMetadata(\n",
    "        v[\"filename\"], id=v[\"id\"], fps=v[\"fps\"],\n",
    "        num_frames=int(v[\"num_frames\"]), width=v[\"width\"], height=v[\"height\"])\n",
    "    for v in video_collection\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's go line by line:\n",
    "\n",
    "Lines 2-4 specify the location of the metadata. You can look at the JSON file yourself by going to https://storage.googleapis.com/esper/dan_olimar/rekall_tutorials/cydet/metadata.json.\n",
    "\n",
    "```Python\n",
    "urllib3.disable_warnings()\n",
    "VIDEO_COLLECTION_BASEURL = \"https://storage.googleapis.com/esper/dan_olimar/rekall_tutorials/cydet\"\n",
    "VIDEO_METADATA_FILENAME = 'metadata.json'\n",
    "```\n",
    "    \n",
    "Lines 6-7 get the data with an HTTP request and parse it into JSON:\n",
    "\n",
    "```Python\n",
    "req = requests.get(posixpath.join(VIDEO_COLLECTION_BASEURL, VIDEO_METADATA_FILENAME), verify=False)\n",
    "video_collection = sorted(req.json(), key=lambda vm: vm['filename'])\n",
    "```\n",
    "\n",
    "At this point, `metadata_json` is a list of Python objects, with information about each video's filename, FPS, width, height, and number of frames. We can loop through this list and construct a list of `VideoMetadata` objects with that information:\n",
    "\n",
    "```Python\n",
    "video_metadata = [\n",
    "    VideoMetadata(\n",
    "        v[\"filename\"], id=v[\"id\"], fps=v[\"fps\"],\n",
    "        num_frames=v[\"num_frames\"], width=v[\"width\"], height=v[\"height\"])\n",
    "    for v in video_collection\n",
    "]\n",
    "```\n",
    "    \n",
    "`VideoMetadata` objects are constructed by passing in `path`, `id`, `fps`, `num_frames`, `width`, and `height`. The `path` is used by Vgrid and a fileserver to serve the video, and `id` is a key that links visual bounding box metadata to the videos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Aside: Visualizing videos directly.\n",
    "\n",
    "Now that we've loaded in video-level metadata, we can visualize the videos in Vgrid directly.\n",
    "\n",
    "#### Again, click to expand the thumbnails. Then use `;` to play the videos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "90f2aff171a442728bb7b83627a21b10",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VGridWidget(vgrid_spec={'compressed': True, 'data': b'x\\x9c\\xddRMo\\xc20\\x0c\\xfd+(\\xe7\\xa9\\x1f@A\\xe3\\xb8\\xe3\\xa…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "vgrid_spec = VGridSpec(\n",
    "    video_meta = video_metadata,\n",
    "    vis_format = VideoBlockFormat(imaps = None, video_meta = video_metadata),\n",
    "    video_endpoint = 'https://storage.googleapis.com/esper/dan_olimar/rekall_tutorials/cydet'\n",
    ")\n",
    "VGridWidget(vgrid_spec = vgrid_spec.to_json_compressed())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Going line by line:\n",
    "\n",
    "Lines 1-5 specify a Vgrid spec for the widget:\n",
    "\n",
    "```Python\n",
    "vgrid_spec = VGridSpec(\n",
    "    video_meta = video_metadata,\n",
    "    vis_format = VideoBlockFormat(imaps = None, video_meta = video_metadata),\n",
    "    video_endpoint = 'https://storage.googleapis.com/esper/dan_olimar/rekall_tutorials/cydet'\n",
    ")\n",
    "```\n",
    "    \n",
    "The `video_meta` option takes in a list of per-video metadata. `vis_format` specifies how the individual blocks in Vgrid should be drawn, along with what to draw on them. In this case, we are using `VideoBlockFormat` and passing in `None` for `imaps` and `video_metadata` for `video_meta`. This will automatically create one block for each video in `video_meta`. Later one, we'll see how we can use it to draw the spatial metadata as well. Finally, `video_endpoint` specifies that we should look for the videos on the `olimar` server.\n",
    "\n",
    "Finally, line 6 creates the widget and displays it in our Jupyter environment:\n",
    "\n",
    "```Python\n",
    "VGridWidget(vgrid_spec = vgrid_spec.to_json_compressed())\n",
    "```\n",
    "    \n",
    "We pass the spec to the Vgrid widget as compressed JSON. Since it's the last line of the cell, it gets displayed below the cell automatically."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Bounding Boxes from Pickle files\n",
    "\n",
    "But as we saw earlier, we can do a lot more than just look at videos if we have some spatial metadata to associate with the videos.\n",
    "\n",
    "**NB in your applications, you'll load data from your own data sources -- however you computed them!**\n",
    "\n",
    "###  This code loads bounding box data associated with each video from olimar:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "maskrcnn_bbox_files = [ 'maskrcnn_bboxes_0001.pkl', 'maskrcnn_bboxes_0004.pkl' ]\n",
    "\n",
    "maskrcnn_bboxes = []\n",
    "for bbox_file in maskrcnn_bbox_files:\n",
    "    req = requests.get(posixpath.join(VIDEO_COLLECTION_BASEURL, bbox_file), verify=False)\n",
    "    maskrcnn_bboxes.append(pickle.loads(req.content))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Going line by line:\n",
    "\n",
    "Line 1 specifies the names of the metadata files on the server:\n",
    "\n",
    "```Python\n",
    "maskrcnn_bbox_files = [ 'maskrcnn_bboxes_0001.pkl', 'maskrcnn_bboxes_0004.pkl' ]\n",
    "```\n",
    "    \n",
    "In this case, we've pre-loaded bounding box metadata into `maskrcnn_bboxes_0001.pkl` and `maskrcnn_bboxes_0004.pkl`. Each Pickle file contains all the bounding boxes for the corresponding video.\n",
    "\n",
    "Lines 3-6 make HTTP requests to the server and parse the Pickle files:\n",
    "\n",
    "```Python\n",
    "maskrcnn_bboxes = []\n",
    "for bbox_file in maskrcnn_bbox_files:\n",
    "    req = requests.get(posixpath.join(VIDEO_COLLECTION_BASEURL, bbox_file), verify=False)\n",
    "    maskrcnn_bboxes.append(pickle.loads(req.content))\n",
    "```\n",
    "\n",
    "Line 5 specifies the path (join the base URL to the specific metadata file), and line 6 specifies that we should parse the Pickle file.\n",
    "\n",
    "If you manually inspect the parsed objects, you'll see that each one has the following format:\n",
    "\n",
    "```Python\n",
    "[\n",
    "    [\n",
    "        [\n",
    "            x1: float,\n",
    "            y1: float,\n",
    "            x2: float,\n",
    "            y2: float,\n",
    "            class: string,\n",
    "            score: float,\n",
    "            image_name: string\n",
    "        ], # for each bounding box in the frame\n",
    "        ...\n",
    "    ], # for each frame\n",
    "    ...\n",
    "]\n",
    "```\n",
    "    \n",
    "In other words, `maskrcnn_bboxes[0][frame][i]` contains Bbox `i` from frame `frame` in the first video."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[644.10205078125,\n",
       " 116.60777282714844,\n",
       " 745.7400512695312,\n",
       " 157.728515625,\n",
       " 'car',\n",
       " 0.9951943755149841,\n",
       " '000000011.png']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "maskrcnn_bboxes[0][10][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Bounding Boxes into Rekall\n",
    "\n",
    "Now that we've loaded our bounding boxes from the server, we can load them into Rekall."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "maskrcnn_bboxes_ism = IntervalSetMapping({\n",
    "    vm.id: IntervalSet([\n",
    "        Interval(\n",
    "            Bounds3D(\n",
    "                t1 = frame_num / vm.fps,\n",
    "                t2 = (frame_num + 1) / vm.fps,\n",
    "                x1 = bbox[0] / vm.width,\n",
    "                x2 = bbox[2] / vm.width,\n",
    "                y1 = bbox[1] / vm.height,\n",
    "                y2 = bbox[3] / vm.height\n",
    "            ),\n",
    "            payload = {\n",
    "                'class': bbox[4],\n",
    "                'score': bbox[5],\n",
    "                'spatial_type': SpatialType_Bbox(text=bbox[4])\n",
    "            }\n",
    "        )\n",
    "        for frame_num, bboxes_in_frame in enumerate(maskrcnn_frame_list)\n",
    "        for bbox in bboxes_in_frame\n",
    "    ])\n",
    "    for vm, maskrcnn_frame_list in zip(video_metadata, maskrcnn_bboxes)\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This cell contains Rekall's core programmatic abstractions, so let's go line by line again.\n",
    "    \n",
    "### The core abstraction of Rekall is an `Interval`, which contains a `Bounds` and a payload\n",
    "\n",
    "![video_volume_v2.png](https://storage.googleapis.com/esper/dan_olimar/rekall_tutorials/videovolume_v2.png)\n",
    "\n",
    "The `Bounds` contains 3D spatial co-ordinates, while the payload contains other metadata about each `Interval`; in this case, each `Interval` corresponds to a bounding box (`t1` and `t2` in seconds, spatial co-ordinates in co-ordinates relative to the frame size), and the payload contains class information and the confidence score for each bounding box:\n",
    "\n",
    "```Python\n",
    "Interval(\n",
    "    Bounds3D(\n",
    "        t1 = frame_num / vm.fps,\n",
    "        t2 = (frame_num + 1) / vm.fps,\n",
    "        x1 = bbox[0] / vm.width,\n",
    "        x2 = bbox[2] / vm.width,\n",
    "        y1 = bbox[1] / vm.height,\n",
    "        y2 = bbox[3] / vm.height\n",
    "    ),\n",
    "    payload = {\n",
    "        'class': bbox[4],\n",
    "        'score': bbox[5],\n",
    "        'spatial_type': SpatialType_Bbox(text=bbox[4])\n",
    "    }\n",
    ")\n",
    "```\n",
    "    \n",
    "Notice that we convert timestamps from frame numbers to seconds by dividing by FPS, and from pixel co-ordinates to frame-relative co-ordinates by diving by width and height (`vm` is defined by the generator at the bottom of the original code).\n",
    "\n",
    "We also set the `spatial_type` of the payload for visualization -- the `text` value that gets passed in is used to write the text on the bounding box.\n",
    "    \n",
    "### An `IntervalSet` is a collection of related `Interval`s\n",
    "\n",
    "We create an `IntervalSet` by passing in a list of `Interval`s. In this case, we create an `IntervalSet` for each video by looping through each frame (first generator), and through all the bounding boxes for the frame (second generator):\n",
    "\n",
    "```Python\n",
    "IntervalSet(\n",
    "    [\n",
    "        Interval(\n",
    "            ...\n",
    "        )\n",
    "        for frame_num, bboxes_in_frame in enumerate(maskrcnn_frame_list)\n",
    "        for bbox in bboxes_in_frame\n",
    "    ]\n",
    ")\n",
    "```\n",
    "\n",
    "For those less familiar with Python, this code is roughly equivalent to something like this:\n",
    "\n",
    "```Python\n",
    "arr = []\n",
    "for frame_num in range(0, len(maskrcnn_frame_list)):\n",
    "    bboxes_in_frame = maskrcnn_frame_list[frame_num]\n",
    "    for bbox in bboxes_in_frame:\n",
    "        arr.append(Interval(...))\n",
    "IntervalSet(arr)\n",
    "```\n",
    "\n",
    "### An `IntervalSetMapping` organizes `IntervalSet`s from different domains\n",
    "\n",
    "Finally, we organize `IntervalSet`s from different videos using an `IntervalSetMapping`, which maps from keys to `IntervalSet`. We create one by passing in a `dict` with one entry for each metadata object in `video_metadata` (notice that we rely on `video_metadata` and `maskrcnn_bboxes` being in the same order):\n",
    "\n",
    "```Python\n",
    "maskrcnn_bboxes_ism = IntervalSetMapping({\n",
    "    vm.id: IntervalSet([...])\n",
    "    for vm, maskrcnn_frame_list in zip(video_metadata, maskrcnn_bboxes)\n",
    "})\n",
    "```\n",
    "\n",
    "In this case, we are mapping from the video ID to the `IntervalSet` with that video's bounding boxes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Display videos with bounding box metadata in Vgrid\n",
    "\n",
    "Finally, we can display the bounding box metadata drawn over the video metadata using Vgrid. To see more documentation about the Vgrid API, check out the [Vgrid documentation](https://github.com/scanner-research/vgrid#javascript-and-python)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2efc84dbff98489590666bf5087e00b4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VGridWidget(vgrid_spec={'compressed': True, 'data': b'x\\x9c\\xcc\\xbd\\xdb\\xae&K\\x92\\x9c\\xf7*D_\\x0bB\\x9c\\x0f\\xba\\…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Visualize the data\n",
    "vgrid_spec = VGridSpec(\n",
    "    video_meta = video_metadata,\n",
    "    vis_format = VideoBlockFormat(imaps = [\n",
    "        ('bboxes', maskrcnn_bboxes_ism)\n",
    "    ]),\n",
    "    video_endpoint = VIDEO_COLLECTION_BASEURL\n",
    ")\n",
    "VGridWidget(vgrid_spec = vgrid_spec.to_json_compressed())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again, line by line:\n",
    "\n",
    "Lines 2-8 specify a VGridSpec for the widget:\n",
    "\n",
    "```Python\n",
    "vgrid_spec = VGridSpec(\n",
    "    video_meta = video_metadata,\n",
    "    vis_format = VideoBlockFormat(imaps = [\n",
    "        ('bboxes', maskrcnn_bboxes_ism)\n",
    "    ]),\n",
    "    video_endpoint = VIDEO_COLLECTION_BASEURL\n",
    ")\n",
    "```\n",
    "    \n",
    "This is the same as when we visualized videos on their own, except this time we are passing `imaps` into `VideoBlockFormat`. This argument expects a list of pairs of `(String, IntervalSetMapping)`. In this case, we are only passing in a single `IntervalSetMapping`.\n",
    "\n",
    "Note that the ID's in `video_metadata` match the keys in the `maskrcnn_bboxes_ism` that we created earlier. Vgrid uses this mapping to know what bounding boxes to draw on which videos.\n",
    "\n",
    "Line 9 passes the spec (with data) as compressed JSON and creates a VGrid Jupyter widget with the data. Since it's the last line of the cell, it gets displayed below the cell automatically."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualizing Multiple Tracks\n",
    "\n",
    "Now that we have a handle on visualizing `IntervalSetMapping`s with Vgrid, let's use some of Rekall's functionality to display a more meaningful visualization.\n",
    "\n",
    "Let's use the filter operation to filter for different classes. This will create four different `IntervalSetMapping` objects, each of which corresponds to different object categories:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "object_names = [\n",
    "    'person',\n",
    "    'car',\n",
    "    'truck',\n",
    "    'traffic light'\n",
    "]\n",
    "object_isms = [\n",
    "    maskrcnn_bboxes_ism.filter(lambda interval: interval['payload']['class'] == object_name)\n",
    "    for object_name in object_names\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above code creates a list of `IntervalSetMapping`s, each of which corresponds to a different object. The first `IntervalsetMapping` of `object_isms` contains all the bounding boxes with the `person` class, the second one contains all the bounding boxes with the `car` class, etc.\n",
    "\n",
    "This code visualizes the different `IntervalSetMapping`s. Each `IntervalSetMapping` will have a different track on the timeline and be visualized with a different color. Notice that we pass in more items into the `imaps` argument of `VideoBlockFormat`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4cdd268dca6f419fa5d77ee8373a42a3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VGridWidget(vgrid_spec={'compressed': True, 'data': b'x\\x9c\\xcc\\xbd\\xcb\\xae%Krm\\xf7+\\x17\\xd5\\x16\\x08\\x7f?\\xd4\\…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "vgrid_spec = VGridSpec(\n",
    "    video_meta = video_metadata,\n",
    "    vis_format = VideoBlockFormat(imaps = [\n",
    "        (\n",
    "            object_name,\n",
    "            ism\n",
    "        )\n",
    "        for ism, object_name in zip(object_isms, object_names)\n",
    "    ]),\n",
    "    video_endpoint = 'https://storage.googleapis.com/esper/dan_olimar/rekall_tutorials/cydet'\n",
    ")\n",
    "VGridWidget(vgrid_spec = vgrid_spec.to_json_compressed())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# More Visualization Formats\n",
    "\n",
    "Vgrid also provides a few other visualization formats. Check out Vgrid's [visualization formats](https://github.com/scanner-research/vgrid/blob/master/vgridpy/vgrid/vis_format.py) for more examples.\n",
    "\n",
    "Here's a useful one - let's have a block for every high confidence (score above `0.99`) person detection in our videos: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "82b69244fb7b4b3298626c47fbc20da3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VGridWidget(vgrid_spec={'compressed': True, 'data': b'x\\x9c\\xe4\\xbd\\xdd\\xaem\\xc9q\\xa5\\xf7*\\r^\\x0bD\\xfeG\\xa6/\\x…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "vgrid_spec = VGridSpec(\n",
    "    video_meta = video_metadata,\n",
    "    vis_format = FlatFormat(maskrcnn_bboxes_ism.filter(\n",
    "        lambda interval: (interval['payload']['class'] == 'person' and\n",
    "                          interval['payload']['score'] > 0.99)\n",
    "    ).dilate(1.0)),\n",
    "    video_endpoint = 'https://storage.googleapis.com/esper/dan_olimar/rekall_tutorials/cydet'\n",
    ")\n",
    "VGridWidget(vgrid_spec = vgrid_spec.to_json_compressed())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above visualization format (`FlatFormat`) creates one Vgrid block for each `Interval`. We dilate the temporal dimension by 1 second just to compensate for inaccurate frame loading in-browser."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Congratulations!\n",
    "\n",
    "You now have an in-depth understanding of how to load data into Rekall and visualize data using Vgrid. For more ideas of what you can do with Rekall, check out the [tech report](http://www.danfu.org/projects/rekall-tech-report/) and the [API documentation](https://rekallpy.readthedocs.io/en/latest/?badge=latest)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
